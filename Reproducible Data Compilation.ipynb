{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Presidential-Election-Data\" data-toc-modified-id=\"Presidential-Election-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Presidential Election Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Online-dataset\" data-toc-modified-id=\"Online-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Online dataset</a></span></li><li><span><a href=\"#Web-Scraping\" data-toc-modified-id=\"Web-Scraping-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Web Scraping</a></span></li></ul></li><li><span><a href=\"#Movie-list-(LGBT-&amp;-Feminism)\" data-toc-modified-id=\"Movie-list-(LGBT-&amp;-Feminism)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Movie list (LGBT &amp; Feminism)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Web-Scraping\" data-toc-modified-id=\"Web-Scraping-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Web Scraping</a></span></li><li><span><a href=\"#Online-dataset\" data-toc-modified-id=\"Online-dataset-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Online dataset</a></span></li><li><span><a href=\"#Online-repository\" data-toc-modified-id=\"Online-repository-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Online repository</a></span></li></ul></li><li><span><a href=\"#Average-Movie-ratings\" data-toc-modified-id=\"Average-Movie-ratings-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Average Movie ratings</a></span></li><li><span><a href=\"#Tweets\" data-toc-modified-id=\"Tweets-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Tweets</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size:25px; color:#A12A0B\"><strong>Popularity of LGBT/Feminist movies by state in US</strong></div> <br>\n",
    "<div style='text-align:center; font-size:20px'>Open Data Mashups</div>\n",
    "<div style=\"text-align:center; font-size:15px\"><em>FALL2018</em></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary packages\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from tqdm import tqdm_notebook\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presidential Election Data\n",
    "There will be 6 election data from 1996 to 2016 (presidential election is held every 4 years). Data from 2000 to 2016 are in standard format online while data of 1996 needs to perform web scraping. \n",
    "\n",
    "- **Data set**: Presidential election data from 1996 to 2016. <br>\n",
    "- **Goal**: Identify conservative, liberal and swing states. For example, if a state voted for Republic Party more than 3 times during 1996 to 2016, it will be labeled as \"Conservative.\" Since there are 6 election years' data, a state voted for one Party 3 times will be labeled as \"Swing.\"<br>\n",
    "- **Output**: 2 columns and 52 rows representing states and their corresponding political tendencies. <br><br>\n",
    "- **Data Source:** \n",
    "    1. Existing csv/xls/xlw files online\n",
    "    2. Web Scraping 1996 election data online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online dataset\n",
    "\n",
    "**Current status**: Standard format files are downloaded. Further step will be conducted to read files into dataframe and identify each state's voting result. <br><br>\n",
    "Online source: https://transition.fec.gov/pubrec/electionresults.shtml <br>\n",
    "It contains data of 2000, 2004, 2008, 2012, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping\n",
    "**Current status**: Webscraping for 1996 voting result is done as shown below. Further step will be conducted to combine results from 1996 - 2016 to determine each state's political tendency. <br><br>\n",
    "\n",
    "Web scraping source: https://transition.fec.gov/pubrec/fe1996/elecpop.htm <br>\n",
    "It contains data from 1996."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse htm file into text content with exception handler\n",
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at 'url' by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                # r.text is the content of the response in unicode, \n",
    "                # and r.content is the content of the response in bytes.\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0}:{1}'.format(url, str(e)))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify whether the source is in HTML/HTM format or not\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Return True if the response seems to be HTML/HTM, Flase otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type']\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None\n",
    "            and content_type.find('html') > -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print error message\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    Print log errors.\n",
    "    \"\"\"\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 1996 presidential ELECTORAL AND POPULAR VOTE \n",
    "url = 'https://transition.fec.gov/pubrec/fe1996/elecpop.htm'\n",
    "response = simple_get(url)\n",
    "if response is not None:\n",
    "    htm = BeautifulSoup(response, 'html.parser')\n",
    "    # cast to string\n",
    "    para = str(htm.find_all('pre'))\n",
    "    temp_content = para[para.find('>AL'):]\n",
    "    table_content = temp_content[1:temp_content.find('<st')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract content of election result into a list. Elements in the list represent rows in the raw data \n",
    "table_content_li = [x for x in table_content.split('\\r\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to nested list for better processing\n",
    "# Fill empty space with 'n' indicating 'not voted' for candidates from a specific state\n",
    "content = []\n",
    "for row in table_content_li[:-1]:\n",
    "    a = row.split('        ')\n",
    "    if a[1] == '':\n",
    "        a[1] = 'n'\n",
    "    if a[2] == '':\n",
    "        a[2] = 'n'\n",
    "    content.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DC', '3', 'n', '     158,220       17,339', '3,611', '      185,726 ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find exception: one list has different length from the rest due to preprocessing\n",
    "content[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exception handling\n",
    "update = content[8][3] + ' ' + content[8][4]\n",
    "content[8][3] = update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DC', '3', 'n', '     158,220       17,339 3,611', '      185,726 ']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the new list meets the requirement\n",
    "temp_row = content[8]\n",
    "del temp_row[4]\n",
    "temp_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace exception with updated list\n",
    "content[8] = temp_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to numpy array then to dataframe\n",
    "df96 = pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column names for dataframe\n",
    "df96.columns = ['State', 'Clinton','Dole','Popular vote','Total Popular vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>Dole</th>\n",
       "      <th>Popular vote</th>\n",
       "      <th>Total Popular vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>n</td>\n",
       "      <td>9</td>\n",
       "      <td>662,165      769,044       92,149</td>\n",
       "      <td>1,534,349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>n</td>\n",
       "      <td>3</td>\n",
       "      <td>80,380      122,746       26,333</td>\n",
       "      <td>241,620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>8</td>\n",
       "      <td>n</td>\n",
       "      <td>653,288      622,073      112,072</td>\n",
       "      <td>1,404,405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>475,171      325,416       69,884</td>\n",
       "      <td>884,262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>54</td>\n",
       "      <td>n</td>\n",
       "      <td>5,119,835    3,828,380      697,847</td>\n",
       "      <td>10,019,484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State Clinton  Dole                            Popular vote  \\\n",
       "0    AL       n     9       662,165      769,044       92,149   \n",
       "1    AK       n     3        80,380      122,746       26,333   \n",
       "2    AZ       8     n       653,288      622,073      112,072   \n",
       "3    AR       6     n       475,171      325,416       69,884   \n",
       "4    CA      54     n     5,119,835    3,828,380      697,847   \n",
       "\n",
       "  Total Popular vote  \n",
       "0         1,534,349   \n",
       "1           241,620   \n",
       "2         1,404,405   \n",
       "3           884,262   \n",
       "4        10,019,484   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df96.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie list (LGBT & Feminism)\n",
    "There are three sources to get a comprehensive movie list with LGBT and Feminism themes as shown below. Each source is handled differently based on format. Overlapping exists among movie lists from three sources as data sources are independent from each other. A final list of related movie names will be generated from them.\n",
    "\n",
    "**Data Source:**<br>\n",
    "1. Web scraping from webpages:\n",
    "    * https://en.wikipedia.org/wiki/List_of_LGBT-related_films\n",
    "    * https://en.wikipedia.org/wiki/Category:Feminist_films\n",
    "2. Online dataset:\n",
    "    * https://www.kaggle.com/juzershakir/tmdb-moviesdataset/home\n",
    "3. Online repository\n",
    "    * http://files.grouplens.org/datasets/movielens/ml-20m-README.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping\n",
    "\n",
    "Wikipedia has lists of LGBT/Feminism topic movies. Since LGBT and Feminism are more of movie topic rather than movie genres like Action, Adventure, Drama, Musical, etc. Movie names on Wikipedia might not be sufficient. That's why further processing on other online dataset is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$30', 'Boys Life 3', '10 Attitudes', 'The 10 Year Plan', '101 Rent Boys', '101 Reykjavík', '2 × 4', '2 Minutes Later', '2 Seconds', '20 Centimeters', '200 American', '2:37', '24 Nights', 'The 24th Day', '29th and Gay', '3', '3 Dancing Slaves', '3-Day Weekend', '3 Kanya', '30 Years from Here', '4th Man Out', '4.3.2.1', '491', '5ive Girls', '50 Ways of Saying Fabulous', '52 Tuesdays', '54', \"'68\", '68 Pages', '7 mujeres, 1 homosexual y Carlos', '8 Women', '8: The Mormon Proposition', '9 Dead Gay Guys', \"À cause d'un garçon\", 'À corps perdu', 'A mi madre le gustan las mujeres', 'À toute vitesse', 'A un dios desconocido', 'Aaron... Albeit a Sex Hero', 'Aban and Khorshid', 'Absent', 'Academy', 'Achilles', 'The Best of Boys in Love', 'Across the Universe', 'AIDS: Doctors and Nurses tell their Stories', 'Ajumma! Are You Krazy???', 'An Act of Valour', 'Adam & Steve', 'Adão e Eva']\n"
     ]
    }
   ],
   "source": [
    "# LGBT related movie\n",
    "origin_page = req.get(\"https://en.wikipedia.org/wiki/List_of_LGBT-related_films\")\n",
    "\n",
    "soup = BeautifulSoup(origin_page.text, \"html.parser\")\n",
    "\n",
    "movie_name1 = ''\n",
    "for element in soup.find_all('a'):\n",
    "    if element.get('title') is not None:\n",
    "        movie_name1 += (str(element.string) + \"***\")\n",
    "\n",
    "# Get movie names part only\n",
    "chunks = movie_name1.split('edit***')\n",
    "for chunk in chunks:\n",
    "    if chunk.startswith('Z'):\n",
    "        z_index = chunks.index(chunk)\n",
    "    if chunk.startswith('$'):\n",
    "        a_index = chunks.index(chunk)\n",
    "\n",
    "movie_list1 = chunks[a_index : z_index+1]\n",
    "\n",
    "# convert each movie into an element of a list\n",
    "movie_names1 = []\n",
    "for movie_chunk in movie_list1:\n",
    "    movie_temp = movie_chunk.split('***')\n",
    "    movie = movie_temp[:-1]\n",
    "    movie_names1.extend(movie)\n",
    "    \n",
    "# a list of all lgbt movie names from Wiki page\n",
    "print(movie_names1[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5 Girls', '9 to 5', '10 Hours of Walking in NYC as a Woman', '10 Things I Hate About You', '20th Century Women', '22 Female Kottayam', '36 Vayadhinile', 'Aadavantha Deivam', 'Aandhi', 'Aaravalli', 'Aayiram Thalai Vaangi Apoorva Chinthamani', 'The Accused', 'Akka Thangai', 'Aletta Jacobs: Het Hoogste Streven', \"Alice Doesn't Live Here Anymore\", 'Alice in Wonderland', 'Aliens', 'All About My Mother', 'Anastasia', 'Anatomy of Hell', 'An Angel at My Table', 'Angry Indian Goddesses', 'Anthuleni Katha', \"Antonia's Line\", 'Arangetram', 'Archana IAS', 'Arth', 'Ask for Jane', 'Assassination Nation', 'The Associate', 'Astitva', 'Attack of the 50 Ft. Woman', 'Aval Appadithan', 'Aval Oru Thodar Kathai', 'Avargal', 'Bad Girls', 'Bad Moms', 'Bagdad Cafe', 'The Ballad of Josie', 'The Ballad of Little Jo', 'Bandit Queen', 'Barb Wire', 'Basic Instinct', 'Battle of the Sexes', 'Becoming Jane', 'Bed and Sofa', 'The Beguiled', 'Big Eyes', 'Bol', 'Born in Flames']\n"
     ]
    }
   ],
   "source": [
    "# Feminism related movies\n",
    "origin_page = req.get(\"https://en.wikipedia.org/wiki/Category:Feminist_films\")\n",
    "\n",
    "soup = BeautifulSoup(origin_page.text, \"html.parser\")\n",
    "\n",
    "movie_name2 = ''\n",
    "for element in soup.find_all('a'):\n",
    "    if element.get('title') is not None:\n",
    "        movie_name2 += (str(element.string) + \"***\")\n",
    "\n",
    "# Get movie names part only\n",
    "chunks = movie_name2.split('***')\n",
    "for chunk in chunks:\n",
    "#     print(chunk)\n",
    "    if chunk.startswith('Nor'):\n",
    "        z_index = chunks.index(chunk)\n",
    "    if chunk.startswith('5'):\n",
    "        a_index = chunks.index(chunk)\n",
    "\n",
    "movie_list2 = chunks[a_index : z_index+1]\n",
    "\n",
    "# convert each movie into an element of a list\n",
    "movie_names2 = []\n",
    "for movie_chunk in movie_list2:\n",
    "    if movie_chunk.endswith(\"film)\"):\n",
    "        movie_names2.append(movie_chunk[0:movie_chunk.index(\"(\")-1])\n",
    "    else:\n",
    "        movie_names2.append(movie_chunk)\n",
    "    \n",
    "# a list of all lgbt movie names from Wiki page\n",
    "print(movie_names2[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online dataset\n",
    "A comprehensive csv data file from kaggle.com with movie names, keywords, budgets, revenue, etc. Keywords indicate the theme and category of the film, which will be used to find LGBT/Feminism movie names.\n",
    "<br><br>\n",
    "**Url**: https://www.kaggle.com/juzershakir/tmdb-moviesdataset/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('/Users/amberwu/Downloads/UIUC/Course FL 2018/Open Data Mashups/Data repo/Movie avg ratings/Movie_rating2/tmdb_movies_data.csv')\n",
    "\n",
    "# keywords for search\n",
    "searchfor = ['lgbt','gay','lesb','strong woman','strong women','femin','homo']\n",
    "\n",
    "# in order to search multiple keywords at a time\n",
    "file_alter = file[file['keywords'].str.contains('|'.join(searchfor), na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 21)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 196 rows of data: 196 movie names\n",
    "file_alter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     The Hunger Games: Mockingjay - Part 2\n",
       "50                                     Carol\n",
       "157                      Ricki and the Flash\n",
       "168                              Suffragette\n",
       "200                                 Freeheld\n",
       "243                            Dirty Weekend\n",
       "300                     The Duke of Burgundy\n",
       "364                            The Girl King\n",
       "521                     Appropriate Behavior\n",
       "538                     The Mask You Live In\n",
       "Name: original_title, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_alter['original_title'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rating = pd.read_csv('/Users/amberwu/Downloads/UIUC/Course FL 2018/Open Data Mashups/Data repo/Movie avg ratings/Movie_rating1/ml-20m/ratings.csv')\n",
    "file_tag = pd.read_csv('/Users/amberwu/Downloads/UIUC/Course FL 2018/Open Data Mashups/Data repo/Movie avg ratings/Movie_rating1/ml-20m/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_movie = pd.read_csv('/Users/amberwu/Downloads/UIUC/Course FL 2018/Open Data Mashups/Data repo/Movie avg ratings/Movie_rating1/ml-20m/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_link=pd.read_csv('/Users/amberwu/Downloads/UIUC/Course FL 2018/Open Data Mashups/Data repo/Movie avg ratings/Movie_rating1/ml-20m/links.csv')\n",
    "file_link.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search keywords from \"tag\" for lgbt/feminist related movies\n",
    "name_tag = file_tag.merge(file_movie, on='movieId')\n",
    "name_tag_alter = name_tag[name_tag['tag'].str.contains('|'.join(searchfor), na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tag_alter.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Movie ratings\n",
    "**Data Source:** <br>\n",
    "- Online repository:\n",
    "    http://files.grouplens.org/datasets/movielens/ml-20m-README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This contains multiple users' ratings on the same movies\n",
    "movie_rating = name_tag_alter.merge(file_rating, on=['userId','movieId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average movie ratings\n",
    "movieid_rating = movie_rating.groupby('movieId')[['rating']].mean()\n",
    "movieid_rating=movieid_rating.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviename_rating = movieid_rating.merge(file_movie, on='movieId')\n",
    "moviename_rating.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviename_rating.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets\n",
    "Using Twitter API to get people's reviews on movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorization\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# Create tweepy object for twitter API\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from Twitter ID file\n",
    "tweet_summary_map = {}\n",
    "nameList = ['being julia', 'brokeback mountain']\n",
    "for movie in nameList:\n",
    "    with open(\"Tweet Data/Tweepy-API-xPath/\"+movie+\".txt\", 'r') as f:\n",
    "        x = f.read().splitlines()\n",
    "    id_list = [line.split('/')[-1] for line in x]\n",
    "    tweet_summary = pd.DataFrame(columns=['Timezone', 'Full Tweet', 'user_name', 'user_location', 'coordinates', 'country_code', 'place'])\n",
    "    tweet_summary.index.name = 'Tweet Time'\n",
    "    for id in tqdm_notebook(id_list):\n",
    "        try:\n",
    "            tweet_info = api.get_status(id, lang = 'en', tweet_mode='extended')\n",
    "            if 'retweeted_status' in dir(tweet_info):\n",
    "                tweet=tweet_info.retweeted_status.full_text\n",
    "            else:\n",
    "                tweet=tweet_info.full_text\n",
    "            if tweet_info.place:\n",
    "                place = tweet_info.place.full_name\n",
    "                country_code = tweet_info.place.country_code\n",
    "            else:\n",
    "                place = None\n",
    "                country_code = None\n",
    "        except:\n",
    "            pass\n",
    "        tweet_summary.loc[tweet_info.created_at] = [tweet_info.user.time_zone, tweet, tweet_info.user.name, tweet_info.user.location, tweet_info.coordinates, country_code, place]\n",
    "    tweet_summary_map[movie] = tweet_summary\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_summary_map['brokeback mountain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_summary_map['being julia']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
